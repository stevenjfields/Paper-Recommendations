{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36f2c2f-7aa7-4fbd-92f1-b83161f4ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "import pandas as pd\n",
    "from cogdl.oag import oagbert\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import os\n",
    "import pymilvus\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87037365-307e-4574-a86d-ae28217a6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_depth = 2\n",
    "ignore_related = True\n",
    "ignore_referenced = False\n",
    "base_works_url = \"https://api.openalex.org/works\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a67f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Article:\n",
    "    # Keeping track of some needed paper details\n",
    "    id: str\n",
    "    title: str\n",
    "    inverted_abstract: Dict[str, List[int]]\n",
    "    authors: List[str]\n",
    "    host_venue: str\n",
    "    affiliations: List[str]\n",
    "    concepts: List[str]\n",
    "    references: List[str]\n",
    "    related: List[str]\n",
    "\n",
    "    def get_abstract(self) -> str:\n",
    "        abstract = dict()\n",
    "        for k, v in self.inverted_abstract.items():\n",
    "            for i in v:\n",
    "                abstract[i] = k\n",
    "\n",
    "        final = \"\"\n",
    "        for i in sorted(abstract.keys()):\n",
    "            final += abstract[i] + \" \"\n",
    "        return final\n",
    "    \n",
    "    def fetch_references_queries(self):\n",
    "        # open alex only allows 50 OR joins per request\n",
    "        queries = list()\n",
    "        for i in range(0, len(self.references), 50):\n",
    "            queries.append('|'.join(self.references[i:i+50]))\n",
    "        return queries\n",
    "    \n",
    "    def fetch_related_queries(self):\n",
    "        # open alex only allows 50 OR joins per request\n",
    "        queries = list()\n",
    "        for i in range(0, len(self.related), 50):\n",
    "            queries.append('|'.join(self.related[i:i+50]))\n",
    "        return queries\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.id}: {self.title}\\n{self.get_abstract()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5213e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_article(result):\n",
    "    work_id = result[\"id\"].split('/')[-1]\n",
    "    title = result[\"title\"]\n",
    "    inverted_abstract = result['abstract_inverted_index']\n",
    "    authors = [authorship['author']['display_name'] for authorship in result['authorships']]\n",
    "    host_venue = result['host_venue']['publisher']\n",
    "    institutions = list()\n",
    "\n",
    "    for authorship in result['authorships']:\n",
    "        for institution in authorship['institutions']: \n",
    "            if institution['display_name'] not in institutions:\n",
    "                institutions.append(institution['display_name'])\n",
    "\n",
    "    concepts = [concept['display_name'] for concept in result['concepts'] if float(concept['score']) > 0.5]\n",
    "    referenced_works = [work.split('/')[-1] for work in result['referenced_works']]\n",
    "    related_works = [work.split('/')[-1] for work in result['related_works']]\n",
    "\n",
    "    return Article(\n",
    "        work_id,\n",
    "        title if title else \"\",\n",
    "        inverted_abstract if inverted_abstract else {\"\": [0]},\n",
    "        authors,\n",
    "        host_venue if host_venue else \"\",\n",
    "        institutions,\n",
    "        concepts,\n",
    "        referenced_works,\n",
    "        related_works\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063dce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymilvus.connections.connect(\n",
    "    alias='default',\n",
    "    host='localhost',\n",
    "    port='19530'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbf02c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    FieldSchema(name='work_id', dtype=DataType.VARCHAR, max_length=32, is_primary=True),\n",
    "    FieldSchema(name='embeddings', dtype=DataType.FLOAT_VECTOR, dim=768)\n",
    "]\n",
    "collection_name = 'Article_Vectors'\n",
    "schema = CollectionSchema(fields, \"Testing\")\n",
    "paper_trail_collection = Collection(collection_name, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fe1aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4acd78-69c6-4c12-b59f-7c23b14f07b5",
   "metadata": {},
   "source": [
    "# Search for Article Title\n",
    "Edit the title variable below to search for a paper. If not exact then returns 25 most relevant papers in the OpenAlex dataset. Select the paper in the dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c333ad3f-a953-494e-a1de-1e3bde69c92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d6b266ce1c425889d88d1de0bd3e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Title: ', options=('RoBERTa: A Robustly Optimized BERT Pretraining Approach', 'BERT: Preâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"BERT\"\n",
    "title = title.replace(\" \", \"%20\")\n",
    "req = requests.get(base_works_url+f\"?filter=title.search:{title}\")\n",
    "response = json.loads(req.content)\n",
    "\n",
    "relevant_titles = [result['title'] for result in response['results']]\n",
    "title_selector = widgets.Dropdown(\n",
    "    options=relevant_titles,\n",
    "    value=relevant_titles[0],\n",
    "    description=\"Title: \"\n",
    ")\n",
    "display(title_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d531b454",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Please select correct title above. If done, run all cells below this one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease select correct title above. If done, run all cells below this one.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Please select correct title above. If done, run all cells below this one."
     ]
    }
   ],
   "source": [
    "raise Exception(\"Please select correct title above. If done, run all cells below this one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c0ca5f4-8341-4d93-be7b-685485140c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = relevant_titles.index(title_selector.value)\n",
    "papers = dict()\n",
    "root_id = response['results'][index]['id'].split('/')[-1]\n",
    "\n",
    "papers[root_id] = fetch_article(response['results'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "60843a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_references = ignore_referenced != True\n",
    "use_related = ignore_related != True\n",
    "\n",
    "related_works: Dict[int, List[Article]] = {}\n",
    "\n",
    "def get_relevant_papers(current_depth: int, previous: List[Article]):\n",
    "    related_works[current_depth] = []\n",
    "    print(current_depth)\n",
    "    for parent in previous:\n",
    "        if use_references and len(parent.references) > 0:\n",
    "            for query in parent.fetch_references_queries():         \n",
    "                req = requests.get(base_works_url + f'?filter=openalex_id:{query}')\n",
    "                res = json.loads(req.content)\n",
    "                for result in res[\"results\"]:\n",
    "                    paper_id = result['id'].split('/')[-1]\n",
    "                    if paper_id not in papers.keys():\n",
    "                        temp = fetch_article(result)\n",
    "                        papers[temp.id] = temp\n",
    "                        related_works[current_depth].append(temp)\n",
    "            \n",
    "        if (use_related and len(parent.related) > 0) or len(parent.references) == 0:\n",
    "            for query in parent.fetch_related_queries():  \n",
    "                req = requests.get(base_works_url + f'?filter=openalex_id:{query}')\n",
    "                res = json.loads(req.content)\n",
    "                for result in res[\"results\"]:\n",
    "                    paper_id = result['id'].split('/')[-1]\n",
    "                    if paper_id not in papers.keys():\n",
    "                        temp = fetch_article(result)\n",
    "                        papers[temp.id] = temp\n",
    "                        related_works[current_depth].append(temp)\n",
    "\n",
    "    if current_depth < max_depth:\n",
    "        get_relevant_papers(current_depth+1, related_works[current_depth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a10c6066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "get_relevant_papers(1, [papers[root_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f04e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = oagbert(\"oagbert-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee4469d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in papers.keys():\n",
    "    curr_paper = papers[key]\n",
    "    input_ids, input_masks, token_type_ids, masked_lm_labels, position_ids, position_ids_second, masked_positions, num_spans = model.build_inputs(\n",
    "        title=curr_paper.title, \n",
    "        abstract=curr_paper.get_abstract(), \n",
    "        venue=curr_paper.host_venue, \n",
    "        authors=curr_paper.authors, \n",
    "        concepts=curr_paper.concepts, \n",
    "        affiliations=curr_paper.affiliations\n",
    "    )\n",
    "\n",
    "    sequence_output, pooled_output = model.bert.forward(\n",
    "        input_ids=torch.LongTensor(input_ids).unsqueeze(0),\n",
    "        token_type_ids=torch.LongTensor(token_type_ids).unsqueeze(0),\n",
    "        attention_mask=torch.LongTensor(input_masks).unsqueeze(0),\n",
    "        output_all_encoded_layers=False,\n",
    "        checkpoint_activations=False,\n",
    "        position_ids=torch.LongTensor(position_ids).unsqueeze(0),\n",
    "        position_ids_second=torch.LongTensor(position_ids_second).unsqueeze(0)\n",
    "    )\n",
    "\n",
    "    pooled_normalized = torch.nn.functional.normalize(pooled_output, p=2, dim=1)\n",
    "\n",
    "    paper_trail_collection.insert([\n",
    "            [key], \n",
    "            [pooled_normalized.tolist()[0]]\n",
    "        ])\n",
    "    \n",
    "paper_trail_collection.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95839e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n"
     ]
    }
   ],
   "source": [
    "print(paper_trail_collection.num_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c07e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPC error: [create_index], <MilvusException: (code=1, message=create index failed, collection is loaded, please release it first)>, <Time:{'RPC start': '2023-02-23 10:39:54.327895', 'RPC error': '2023-02-23 10:39:54.329801'}>\n"
     ]
    },
    {
     "ename": "MilvusException",
     "evalue": "<MilvusException: (code=1, message=create index failed, collection is loaded, please release it first)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m index_params \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmetric_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mIP\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mindex_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mIVF_FLAT\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39mnlist\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m128\u001b[39m}\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 7\u001b[0m paper_trail_collection\u001b[39m.\u001b[39;49mcreate_index(field_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39membeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m, index_params\u001b[39m=\u001b[39;49mindex_params)\n",
      "File \u001b[0;32m~/Desktop/Programming/Independent_Study/venv/lib/python3.8/site-packages/pymilvus/orm/collection.py:953\u001b[0m, in \u001b[0;36mCollection.create_index\u001b[0;34m(self, field_name, index_params, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates index for a specified field, with a index name.\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \n\u001b[1;32m    920\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[39m    Status(code=0, message='')\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    952\u001b[0m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[0;32m--> 953\u001b[0m \u001b[39mreturn\u001b[39;00m conn\u001b[39m.\u001b[39;49mcreate_index(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, field_name, index_params, timeout\u001b[39m=\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Programming/Independent_Study/venv/lib/python3.8/site-packages/pymilvus/decorators.py:109\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m     record_dict[\u001b[39m\"\u001b[39m\u001b[39mRPC error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow())\n\u001b[1;32m    108\u001b[0m     LOGGER\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRPC error: [\u001b[39m\u001b[39m{\u001b[39;00minner_name\u001b[39m}\u001b[39;00m\u001b[39m], \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m, <Time:\u001b[39m\u001b[39m{\u001b[39;00mrecord_dict\u001b[39m}\u001b[39;00m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    110\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mFutureTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    111\u001b[0m     record_dict[\u001b[39m\"\u001b[39m\u001b[39mgRPC timeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow())\n",
      "File \u001b[0;32m~/Desktop/Programming/Independent_Study/venv/lib/python3.8/site-packages/pymilvus/decorators.py:105\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     record_dict[\u001b[39m\"\u001b[39m\u001b[39mRPC start\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow())\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    106\u001b[0m \u001b[39mexcept\u001b[39;00m MilvusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     record_dict[\u001b[39m\"\u001b[39m\u001b[39mRPC error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow())\n",
      "File \u001b[0;32m~/Desktop/Programming/Independent_Study/venv/lib/python3.8/site-packages/pymilvus/decorators.py:136\u001b[0m, in \u001b[0;36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m req_id:\n\u001b[1;32m    135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_onetime_request_id(req_id)\n\u001b[0;32m--> 136\u001b[0m ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/Desktop/Programming/Independent_Study/venv/lib/python3.8/site-packages/pymilvus/decorators.py:85\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         back_off \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(back_off \u001b[39m*\u001b[39m back_off_multiplier, max_back_off)\n\u001b[1;32m     84\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     87\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Desktop/Programming/Independent_Study/venv/lib/python3.8/site-packages/pymilvus/decorators.py:50\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     51\u001b[0m     \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     52\u001b[0m         \u001b[39m# DEADLINE_EXCEEDED means that the task wat not completed\u001b[39;00m\n\u001b[1;32m     53\u001b[0m         \u001b[39m# UNAVAILABLE means that the service is not reachable currently\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         \u001b[39m# Reference: https://grpc.github.io/grpc/python/grpc.html#grpc-status-code\u001b[39;00m\n\u001b[1;32m     55\u001b[0m         \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mcode() \u001b[39m!=\u001b[39m grpc\u001b[39m.\u001b[39mStatusCode\u001b[39m.\u001b[39mDEADLINE_EXCEEDED \u001b[39mand\u001b[39;00m e\u001b[39m.\u001b[39mcode() \u001b[39m!=\u001b[39m grpc\u001b[39m.\u001b[39mStatusCode\u001b[39m.\u001b[39mUNAVAILABLE:\n",
      "File \u001b[0;32m~/Desktop/Programming/Independent_Study/venv/lib/python3.8/site-packages/pymilvus/client/grpc_handler.py:557\u001b[0m, in \u001b[0;36mGrpcHandler.create_index\u001b[0;34m(self, collection_name, field_name, params, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m status \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39mresult()\n\u001b[1;32m    556\u001b[0m \u001b[39mif\u001b[39;00m status\u001b[39m.\u001b[39merror_code \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m MilvusException(status\u001b[39m.\u001b[39merror_code, status\u001b[39m.\u001b[39mreason)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msync\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    560\u001b[0m     index_success, fail_reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait_for_creating_index(collection_name\u001b[39m=\u001b[39mcollection_name,\n\u001b[1;32m    561\u001b[0m                                                               index_name\u001b[39m=\u001b[39mindex_name,\n\u001b[1;32m    562\u001b[0m                                                               timeout\u001b[39m=\u001b[39mtimeout, field_name\u001b[39m=\u001b[39mfield_name)\n",
      "\u001b[0;31mMilvusException\u001b[0m: <MilvusException: (code=1, message=create index failed, collection is loaded, please release it first)>"
     ]
    }
   ],
   "source": [
    "index_params = {\n",
    "    \"metric_type\": \"IP\",\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"params\": {\"nlist\": 128}\n",
    "}\n",
    "\n",
    "paper_trail_collection.create_index(field_name=\"embeddings\", index_params=index_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c3f55c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_trail_collection.load()\n",
    "root_paper_embeddings = paper_trail_collection.query(\n",
    "    expr = f'work_id == \"{root_id}\"',\n",
    "    output_fields=['embeddings']\n",
    ")\n",
    "root_paper_embeddings = torch.Tensor(root_paper_embeddings[0]['embeddings'])\n",
    "root_paper_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6af4ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_trail_collection.load()\n",
    "root_paper_embeddings = paper_trail_collection.query(\n",
    "    expr = f'work_id == \"{root_id}\"',\n",
    "    output_fields=['embeddings']\n",
    ")\n",
    "root_paper_embeddings = torch.Tensor([root_paper_embeddings[0]['embeddings']])\n",
    "\n",
    "paper_keys = list(papers.keys())\n",
    "paper_keys.remove(root_id)\n",
    "\n",
    "cols = [\"id\", \"title\", \"score\"]\n",
    "similarities = pd.DataFrame(columns=cols)\n",
    "\n",
    "for key in paper_keys:\n",
    "    paper_embeddings = paper_trail_collection.query(\n",
    "        expr = f'work_id == \"{key}\"',\n",
    "        output_fields=['embeddings']\n",
    "    )\n",
    "    paper_embeddings = torch.Tensor([paper_embeddings[0]['embeddings']])\n",
    "    sim = torch.mm(root_paper_embeddings, paper_embeddings.transpose(0, 1))\n",
    "    results = {\n",
    "        \"id\": [key],\n",
    "        \"title\": [papers[key].title],\n",
    "        \"score\": [sim.detach().numpy()]\n",
    "    }\n",
    "\n",
    "    similarities = pd.concat([similarities, pd.DataFrame(results)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e052225f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>W2962784628</td>\n",
       "      <td>Neural Machine Translation of Rare Words with ...</td>\n",
       "      <td>[[0.9945146]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>W2963918774</td>\n",
       "      <td>Supervised Learning of Universal Sentence Repr...</td>\n",
       "      <td>[[0.99435556]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>W2153579005</td>\n",
       "      <td>Distributed Representations of Words and Phras...</td>\n",
       "      <td>[[0.9941311]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>W2158139315</td>\n",
       "      <td>Word Representations: A Simple and General Met...</td>\n",
       "      <td>[[0.99392474]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>W2251803266</td>\n",
       "      <td>Don't count, predict! A systematic comparison ...</td>\n",
       "      <td>[[0.9939003]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>W2164019165</td>\n",
       "      <td>Improving Word Representations via Global Cont...</td>\n",
       "      <td>[[0.99379086]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>W1973942085</td>\n",
       "      <td>A structured vector space model for word meani...</td>\n",
       "      <td>[[0.99360996]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>W2153508793</td>\n",
       "      <td>Automatic Evaluation of Translation Quality fo...</td>\n",
       "      <td>[[0.9935808]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>W1897507002</td>\n",
       "      <td>Entailment, intensionality and text understanding</td>\n",
       "      <td>[[0.99333894]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>W2250189634</td>\n",
       "      <td>Linguistic Regularities in Sparse and Explicit...</td>\n",
       "      <td>[[0.99310374]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>W2978017171</td>\n",
       "      <td>DistilBERT, a distilled version of BERT: small...</td>\n",
       "      <td>[[0.9930416]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>W1632114991</td>\n",
       "      <td>Building a Large Annotated Corpus of English: ...</td>\n",
       "      <td>[[0.9929921]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>W2584341106</td>\n",
       "      <td>Memory Networks</td>\n",
       "      <td>[[0.9929254]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>W2163455955</td>\n",
       "      <td>Seeing stars</td>\n",
       "      <td>[[0.9928559]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>W2123442489</td>\n",
       "      <td>The Stanford CoreNLP Natural Language Processi...</td>\n",
       "      <td>[[0.9927528]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>W2626778328</td>\n",
       "      <td>Attention Is All You Need</td>\n",
       "      <td>[[0.9926431]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>W2970771982</td>\n",
       "      <td>SciBERT: A Pretrained Language Model for Scien...</td>\n",
       "      <td>[[0.99249554]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>W1933349210</td>\n",
       "      <td>VQA: Visual Question Answering</td>\n",
       "      <td>[[0.99249375]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>W2102381086</td>\n",
       "      <td>Introduction to WordNet: An On-line Lexical Da...</td>\n",
       "      <td>[[0.9924575]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>W2970325945</td>\n",
       "      <td>EED: Extended Edit Distance Measure for Machin...</td>\n",
       "      <td>[[0.99243146]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>W1854884267</td>\n",
       "      <td>SimLex-999: Evaluating Semantic Models With (G...</td>\n",
       "      <td>[[0.9923829]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>W1924770834</td>\n",
       "      <td>Empirical evaluation of gated recurrent neural...</td>\n",
       "      <td>[[0.9923639]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>W2141532438</td>\n",
       "      <td>An evaluation exercise for word alignment</td>\n",
       "      <td>[[0.9923066]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>W1956340063</td>\n",
       "      <td>CIDEr: Consensus-based image description evalu...</td>\n",
       "      <td>[[0.99229145]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>W2156985047</td>\n",
       "      <td>A Systematic Comparison of Various Statistical...</td>\n",
       "      <td>[[0.9922793]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "76   W2962784628  Neural Machine Translation of Rare Words with ...   \n",
       "12   W2963918774  Supervised Learning of Universal Sentence Repr...   \n",
       "26   W2153579005  Distributed Representations of Words and Phras...   \n",
       "40   W2158139315  Word Representations: A Simple and General Met...   \n",
       "41   W2251803266  Don't count, predict! A systematic comparison ...   \n",
       "43   W2164019165  Improving Word Representations via Global Cont...   \n",
       "141  W1973942085  A structured vector space model for word meani...   \n",
       "317  W2153508793  Automatic Evaluation of Translation Quality fo...   \n",
       "182  W1897507002  Entailment, intensionality and text understanding   \n",
       "47   W2250189634  Linguistic Regularities in Sparse and Explicit...   \n",
       "165  W2978017171  DistilBERT, a distilled version of BERT: small...   \n",
       "184  W1632114991  Building a Large Annotated Corpus of English: ...   \n",
       "173  W2584341106                                    Memory Networks   \n",
       "11   W2163455955                                       Seeing stars   \n",
       "255  W2123442489  The Stanford CoreNLP Natural Language Processi...   \n",
       "303  W2626778328                          Attention Is All You Need   \n",
       "320  W2970771982  SciBERT: A Pretrained Language Model for Scien...   \n",
       "212  W1933349210                     VQA: Visual Question Answering   \n",
       "105  W2102381086  Introduction to WordNet: An On-line Lexical Da...   \n",
       "334  W2970325945  EED: Extended Edit Distance Measure for Machin...   \n",
       "404  W1854884267  SimLex-999: Evaluating Semantic Models With (G...   \n",
       "343  W1924770834  Empirical evaluation of gated recurrent neural...   \n",
       "298  W2141532438          An evaluation exercise for word alignment   \n",
       "304  W1956340063  CIDEr: Consensus-based image description evalu...   \n",
       "290  W2156985047  A Systematic Comparison of Various Statistical...   \n",
       "\n",
       "              score  \n",
       "76    [[0.9945146]]  \n",
       "12   [[0.99435556]]  \n",
       "26    [[0.9941311]]  \n",
       "40   [[0.99392474]]  \n",
       "41    [[0.9939003]]  \n",
       "43   [[0.99379086]]  \n",
       "141  [[0.99360996]]  \n",
       "317   [[0.9935808]]  \n",
       "182  [[0.99333894]]  \n",
       "47   [[0.99310374]]  \n",
       "165   [[0.9930416]]  \n",
       "184   [[0.9929921]]  \n",
       "173   [[0.9929254]]  \n",
       "11    [[0.9928559]]  \n",
       "255   [[0.9927528]]  \n",
       "303   [[0.9926431]]  \n",
       "320  [[0.99249554]]  \n",
       "212  [[0.99249375]]  \n",
       "105   [[0.9924575]]  \n",
       "334  [[0.99243146]]  \n",
       "404   [[0.9923829]]  \n",
       "343   [[0.9923639]]  \n",
       "298   [[0.9923066]]  \n",
       "304  [[0.99229145]]  \n",
       "290   [[0.9922793]]  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.sort_values(by=\"score\", ascending=False).head(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da0f4927",
   "metadata": {},
   "source": [
    "# Print Root Paper Abstract and 5 most similar papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f80b726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2970641574: Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\n",
      "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods. \n"
     ]
    }
   ],
   "source": [
    "print(papers[root_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "42ff32c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2962784628: Neural Machine Translation of Rare Words with Subword Units\n",
      "Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character ngram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English!German and English!Russian by up to 1.1 and 1.3 BLEU, respectively. \n",
      "\n",
      "\n",
      "\n",
      "W2963918774: Supervised Learning of Universal Sentence Representations from Natural Language Inference Data\n",
      "Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available. \n",
      "\n",
      "\n",
      "\n",
      "W2153579005: Distributed Representations of Words and Phrases and their Compositionality\n",
      "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling.\n",
      "\n",
      "An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of Canada and cannot be easily combined to obtain Air Canada. Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible. \n",
      "\n",
      "\n",
      "\n",
      "W2158139315: Word Representations: A Simple and General Method for Semi-Supervised Learning\n",
      "If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/ \n",
      "\n",
      "\n",
      "\n",
      "W2251803266: Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors\n",
      "Context-predicting models (more commonly known as embeddings or neural language models) are the new kids on the distributional semantics block. Despite the buzz surrounding these models, the literature is still lacking a systematic comparison of the predictive models with classic, count-vector-based distributional semantic approaches. In this paper, we perform such an extensive evaluation, on a wide range of lexical semantics tasks and across many parameter settings. The results, to our own surprise, show that the buzz is fully justified, as the context-predicting models obtain a thorough and resounding victory against their count-based counterparts. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ids = similarities.sort_values(by=\"score\", ascending=False).head(5)[\"id\"]\n",
    "for id in ids.values:\n",
    "    print(papers[id])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "923d854d",
   "metadata": {},
   "source": [
    "# Testing Milvus Search Functionality (cosine similarity)\n",
    "\n",
    "Slightly different results from above, but still very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "74433663",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_paper_embeddings = root_paper_embeddings.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dafa580f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root_paper_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68839ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}, \"offset\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2ec132e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = paper_trail_collection.search(\n",
    "\tdata=[root_paper_embeddings], \n",
    "\tanns_field=\"embeddings\", \n",
    "\tparam=search_params,\n",
    "\tlimit=10, \n",
    "\texpr=None,\n",
    "\tconsistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "033d179b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W2115792525', 'W2130237711', 'W2158139315', 'W2251803266', 'W2164019165', 'W2963216553', 'W2949547296', 'W2085766370', 'W2087556608', 'W2131744502']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b6e4e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9941201210021973, 0.9940099120140076, 0.9939247369766235, 0.9939004182815552, 0.9937907457351685, 0.9937602281570435, 0.9937376976013184, 0.9937025308609009, 0.9936977624893188, 0.9936720132827759]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b65f9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2115792525: The Berkeley FrameNet Project\n",
      "FrameNet is a three-year NSF-supported project in corpus-based computational lexicography, now in its second year (NSF IRI-9618838, Tools for Lexicon Building). The project's key features are (a) a commitment to corpus evidence for semantic and syntactic generalizations, and (b) the representation of the valences of its target words (mostly nouns, adjectives, and verbs) in which the semantic portion makes use of semantics. The resulting database will contain (a) descriptions of the semantic frames underlying the meanings of the words described, and (b) the valence representation (semantic and syntactic) of several thousand words and phrases, each accompanied by (c) a representative collection of annotated corpus attestations, which jointly exemplify the observed linkings between frame elements and their syntactic realizations (e.g. grammatical function, phrase type, and other syntactic traits). This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work. \n",
      "Distance: 0.9941201210021973\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'W2130237711'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mprint\u001b[39m(papers[results[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mids[i]])\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDistance: \u001b[39m\u001b[39m{\u001b[39;00mresults[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdistances[i]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'W2130237711'"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(papers[results[0].ids[i]])\n",
    "    print(f\"Distance: {results[0].distances[i]}\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "267a7ab8",
   "metadata": {},
   "source": [
    "I accidentally nuked the previous papers, but the embeddings were kept in the Milvus instance. Since I didn't filter for only direct references to the paper it tried offering similar papers outside the references"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f746478d",
   "metadata": {},
   "source": [
    "# Only Include Direct References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4eea4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_references = papers[root_id].references if papers[root_id].references else papers[root_id].related # this is gross\n",
    "direct_references = [f'\"{ref}\"' for ref in direct_references]\n",
    "direct_references = ', '.join(direct_references)\n",
    "\n",
    "results = paper_trail_collection.search(\n",
    "\tdata=[root_paper_embeddings], \n",
    "\tanns_field=\"embeddings\", \n",
    "\tparam=search_params,\n",
    "\tlimit=10, \n",
    "\texpr=f\"work_id in [{direct_references}]\",\n",
    "\tconsistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bf7e7056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2963341956: \n",
      "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement). \n",
      "Distance: 0.9912476539611816\n",
      "\n",
      "\n",
      "W2963846996: A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference\n",
      "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement. \n",
      "Distance: 0.9911103248596191\n",
      "\n",
      "\n",
      "W2593864460: Billion-scale similarity search with GPUs\n",
      "Similarity search finds application in specialized database systems handling complex data such as images or videos, which are typically represented by high-dimensional features and require specific indexing structures. This paper tackles the problem of better utilizing GPUs for this task. While GPUs excel at data-parallel tasks, prior approaches are bottlenecked by algorithms that expose less parallelism, such as k-min selection, or make poor use of the memory hierarchy. \n",
      "We propose a design for k-selection that operates at up to 55% of theoretical peak performance, enabling a nearest neighbor implementation that is 8.5x faster than prior GPU state of the art. We apply it in different similarity search scenarios, by proposing optimized design for brute-force, approximate and compressed-domain search based on product quantization. In all these setups, we outperform the state of the art by large margins. Our implementation enables the construction of a high accuracy k-NN graph on 95 million images from the Yfcc100M dataset in 35 minutes, and of a graph connecting 1 billion vectors in less than 12 hours on 4 Maxwell Titan X GPUs. We have open-sourced our approach for the sake of comparison and reproducibility. \n",
      "Distance: 0.9907121062278748\n",
      "\n",
      "\n",
      "W2794557536: Universal Sentence Encoder\n",
      "We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub. \n",
      "Distance: 0.9901109933853149\n",
      "\n",
      "\n",
      "W2963804993: Learning Distributed Representations of Sentences from Unlabelled Data\n",
      "Unsupervised methods for learning distributed representations of words are ubiquitous in today's NLP research, but far less is known about the best ways to learn distributed phrase or sentence representations from unlabelled data. This paper is a systematic comparison of models that learn such representations. We find that the optimal approach depends critically on the intended application. Deeper, more complex models are preferable for representations to be used in supervised systems, but shallow log-linear models work best for building representation spaces that can be decoded with simple spatial distance metrics. We also propose two new unsupervised representation-learning objectives designed to optimise the trade-off between training time, domain portability and performance. \n",
      "Distance: 0.9899096488952637\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(papers[results[0].ids[i]])\n",
    "    print(f\"Distance: {results[0].distances[i]}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad6f02c4897e5a2f50ed3c5fec7e665ad608d4dc358906e6dd46ab054316280e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
