{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36f2c2f-7aa7-4fbd-92f1-b83161f4ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "import pandas as pd\n",
    "from cogdl.oag import oagbert\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import os\n",
    "import pymilvus\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87037365-307e-4574-a86d-ae28217a6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_depth = 2\n",
    "ignore_related = True\n",
    "ignore_referenced = False\n",
    "base_works_url = \"https://api.openalex.org/works\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a67f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Article:\n",
    "    # Keeping track of some needed paper details\n",
    "    id: str\n",
    "    title: str\n",
    "    inverted_abstract: Dict[str, List[int]]\n",
    "    authors: List[str]\n",
    "    host_venue: str\n",
    "    affiliations: List[str]\n",
    "    concepts: List[str]\n",
    "    references: List[str]\n",
    "    related: List[str]\n",
    "\n",
    "    def get_abstract(self) -> str:\n",
    "        abstract = dict()\n",
    "        for k, v in self.inverted_abstract.items():\n",
    "            for i in v:\n",
    "                abstract[i] = k\n",
    "\n",
    "        final = \"\"\n",
    "        for i in sorted(abstract.keys()):\n",
    "            final += abstract[i] + \" \"\n",
    "        return final\n",
    "    \n",
    "    def fetch_references_queries(self):\n",
    "        # open alex only allows 50 OR joins per request\n",
    "        queries = list()\n",
    "        for i in range(0, len(self.references), 50):\n",
    "            queries.append('|'.join(self.references[i:i+50]))\n",
    "        return queries\n",
    "    \n",
    "    def fetch_related_queries(self):\n",
    "        # open alex only allows 50 OR joins per request\n",
    "        queries = list()\n",
    "        for i in range(0, len(self.related), 50):\n",
    "            queries.append('|'.join(self.related[i:i+50]))\n",
    "        return queries\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.id}: {self.title}\\n{self.get_abstract()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5213e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_article(result):\n",
    "    work_id = result[\"id\"].split('/')[-1]\n",
    "    title = result[\"title\"]\n",
    "    inverted_abstract = result['abstract_inverted_index']\n",
    "    authors = [authorship['author']['display_name'] for authorship in result['authorships']]\n",
    "    host_venue = result['host_venue']['publisher']\n",
    "    institutions = list()\n",
    "\n",
    "    for authorship in result['authorships']:\n",
    "        for institution in authorship['institutions']: \n",
    "            if institution['display_name'] not in institutions:\n",
    "                institutions.append(institution['display_name'])\n",
    "\n",
    "    concepts = [concept['display_name'] for concept in result['concepts'] if float(concept['score']) > 0.5]\n",
    "    referenced_works = [work.split('/')[-1] for work in result['referenced_works']]\n",
    "    related_works = [work.split('/')[-1] for work in result['related_works']]\n",
    "\n",
    "    return Article(\n",
    "        work_id,\n",
    "        title if title else \"\",\n",
    "        inverted_abstract if inverted_abstract else {\"\": [0]},\n",
    "        authors,\n",
    "        host_venue if host_venue else \"\",\n",
    "        institutions,\n",
    "        concepts,\n",
    "        referenced_works,\n",
    "        related_works\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063dce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymilvus.connections.connect(\n",
    "    alias='default',\n",
    "    host='localhost',\n",
    "    port='19530'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbf02c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    FieldSchema(name='pk', dtype=DataType.VARCHAR, max_length=32, is_primary=True),\n",
    "    FieldSchema(name='embeddings', dtype=DataType.FLOAT_VECTOR, dim=768)\n",
    "]\n",
    "collection_name = 'paper_trail_test'\n",
    "schema = CollectionSchema(fields, \"Testing\")\n",
    "paper_trail_collection = Collection(collection_name, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fe1aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4acd78-69c6-4c12-b59f-7c23b14f07b5",
   "metadata": {},
   "source": [
    "# Search for Article Title\n",
    "Edit the title variable below to search for a paper. If not exact then returns 25 most relevant papers in the OpenAlex dataset. Select the paper in the dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c333ad3f-a953-494e-a1de-1e3bde69c92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f12faf7f8d446b9a4227ee37668d609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Title: ', options=('Attention is All you Need', 'Attention Is All You Need', 'Channel At…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"Attention is all you need\"\n",
    "title = title.replace(\" \", \"%20\")\n",
    "req = requests.get(base_works_url+f\"?filter=title.search:{title}\")\n",
    "response = json.loads(req.content)\n",
    "\n",
    "relevant_titles = [result['title'] for result in response['results']]\n",
    "title_selector = widgets.Dropdown(\n",
    "    options=relevant_titles,\n",
    "    value=relevant_titles[0],\n",
    "    description=\"Title: \"\n",
    ")\n",
    "display(title_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d531b454",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Please select correct title above. If done, run all cells below this one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease select correct title above. If done, run all cells below this one.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Please select correct title above. If done, run all cells below this one."
     ]
    }
   ],
   "source": [
    "raise Exception(\"Please select correct title above. If done, run all cells below this one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0ca5f4-8341-4d93-be7b-685485140c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = relevant_titles.index(title_selector.value)\n",
    "papers = dict()\n",
    "root_id = response['results'][index]['id'].split('/')[-1]\n",
    "\n",
    "papers[root_id] = fetch_article(response['results'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60843a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_references = ignore_referenced != True\n",
    "use_related = ignore_related != True\n",
    "\n",
    "related_works: Dict[int, List[Article]] = {}\n",
    "\n",
    "def get_relevant_papers(current_depth: int, previous: List[Article]):\n",
    "    related_works[current_depth] = []\n",
    "    print(current_depth)\n",
    "    for parent in previous:\n",
    "        if use_references and len(parent.references) > 0:\n",
    "            for query in parent.fetch_references_queries():         \n",
    "                req = requests.get(base_works_url + f'?filter=openalex_id:{query}')\n",
    "                res = json.loads(req.content)\n",
    "                for result in res[\"results\"]:\n",
    "                    paper_id = result['id'].split('/')[-1]\n",
    "                    if paper_id not in papers.keys():\n",
    "                        temp = fetch_article(result)\n",
    "                        papers[temp.id] = temp\n",
    "                        related_works[current_depth].append(temp)\n",
    "            \n",
    "        if (use_related and len(parent.related) > 0) or len(parent.references) == 0:\n",
    "            for query in parent.fetch_related_queries():  \n",
    "                req = requests.get(base_works_url + f'?filter=openalex_id:{query}')\n",
    "                res = json.loads(req.content)\n",
    "                for result in res[\"results\"]:\n",
    "                    paper_id = result['id'].split('/')[-1]\n",
    "                    if paper_id not in papers.keys():\n",
    "                        temp = fetch_article(result)\n",
    "                        papers[temp.id] = temp\n",
    "                        related_works[current_depth].append(temp)\n",
    "\n",
    "    if current_depth < max_depth:\n",
    "        get_relevant_papers(current_depth+1, related_works[current_depth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10c6066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "get_relevant_papers(1, [papers[root_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f04e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = oagbert(\"oagbert-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee4469d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./embeddings/\"):\n",
    "    os.mkdir(\"./embeddings/\")\n",
    "\n",
    "files = os.listdir(\"./embeddings/\")\n",
    "files = [file.split('.')[0] for file in files]\n",
    "\n",
    "for key in papers.keys():\n",
    "    curr_paper = papers[key]\n",
    "    input_ids, input_masks, token_type_ids, masked_lm_labels, position_ids, position_ids_second, masked_positions, num_spans = model.build_inputs(\n",
    "        title=curr_paper.title, \n",
    "        abstract=curr_paper.get_abstract(), \n",
    "        venue=curr_paper.host_venue, \n",
    "        authors=curr_paper.authors, \n",
    "        concepts=curr_paper.concepts, \n",
    "        affiliations=curr_paper.affiliations\n",
    "    )\n",
    "\n",
    "    sequence_output, pooled_output = model.bert.forward(\n",
    "        input_ids=torch.LongTensor(input_ids).unsqueeze(0),\n",
    "        token_type_ids=torch.LongTensor(token_type_ids).unsqueeze(0),\n",
    "        attention_mask=torch.LongTensor(input_masks).unsqueeze(0),\n",
    "        output_all_encoded_layers=False,\n",
    "        checkpoint_activations=False,\n",
    "        position_ids=torch.LongTensor(position_ids).unsqueeze(0),\n",
    "        position_ids_second=torch.LongTensor(position_ids_second).unsqueeze(0)\n",
    "    )\n",
    "\n",
    "    pooled_normalized = torch.nn.functional.normalize(pooled_output, p=2, dim=1)\n",
    "\n",
    "    paper_trail_collection.insert([\n",
    "            [key], \n",
    "            [pooled_normalized.tolist()[0]]\n",
    "        ])\n",
    "    \n",
    "paper_trail_collection.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95839e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(paper_trail_collection.num_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c07e0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_params = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"params\": {\"nlist\": 128}\n",
    "}\n",
    "\n",
    "paper_trail_collection.create_index(field_name=\"embeddings\", index_params=index_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3f55c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_trail_collection.load()\n",
    "root_paper_embeddings = paper_trail_collection.query(\n",
    "    expr = f'pk == \"{root_id}\"',\n",
    "    output_fields=['embeddings']\n",
    ")\n",
    "root_paper_embeddings = torch.Tensor(root_paper_embeddings[0]['embeddings'])\n",
    "root_paper_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6af4ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_trail_collection.load()\n",
    "root_paper_embeddings = paper_trail_collection.query(\n",
    "    expr = f'pk == \"{root_id}\"',\n",
    "    output_fields=['embeddings']\n",
    ")\n",
    "root_paper_embeddings = torch.Tensor([root_paper_embeddings[0]['embeddings']])\n",
    "\n",
    "paper_keys = list(papers.keys())\n",
    "paper_keys.remove(root_id)\n",
    "\n",
    "cols = [\"id\", \"title\", \"score\"]\n",
    "similarities = pd.DataFrame(columns=cols)\n",
    "\n",
    "for key in paper_keys:\n",
    "    paper_embeddings = paper_trail_collection.query(\n",
    "        expr = f'pk == \"{key}\"',\n",
    "        output_fields=['embeddings']\n",
    "    )\n",
    "    paper_embeddings = torch.Tensor([paper_embeddings[0]['embeddings']])\n",
    "    sim = torch.mm(root_paper_embeddings, paper_embeddings.transpose(0, 1))\n",
    "    results = {\n",
    "        \"id\": [key],\n",
    "        \"title\": [papers[key].title],\n",
    "        \"score\": [sim.detach().numpy()]\n",
    "    }\n",
    "\n",
    "    similarities = pd.concat([similarities, pd.DataFrame(results)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e052225f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>W2250489405</td>\n",
       "      <td>Joint Language and Translation Modeling with R...</td>\n",
       "      <td>[[0.99704975]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>W2131462252</td>\n",
       "      <td>A Scalable Hierarchical Distributed Language M...</td>\n",
       "      <td>[[0.9967903]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>W2253807446</td>\n",
       "      <td>Building high-level features using large scale...</td>\n",
       "      <td>[[0.9967419]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>W2964335273</td>\n",
       "      <td>How to Construct Deep Recurrent Neural Networks</td>\n",
       "      <td>[[0.99667966]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>W2120861206</td>\n",
       "      <td>A fast and simple algorithm for training neura...</td>\n",
       "      <td>[[0.99649143]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>W2127141656</td>\n",
       "      <td>Connectionist temporal classification</td>\n",
       "      <td>[[0.9964779]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>W2148708890</td>\n",
       "      <td>A Simple, Fast, and Effective Reparameterizati...</td>\n",
       "      <td>[[0.9963628]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>W179875071</td>\n",
       "      <td>Recurrent neural network based language model</td>\n",
       "      <td>[[0.99634004]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>W3016169217</td>\n",
       "      <td>Neural Tree Indexers for Text Understanding</td>\n",
       "      <td>[[0.9962524]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>W1599016936</td>\n",
       "      <td>The Winograd schema challenge</td>\n",
       "      <td>[[0.9961974]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>W2251939518</td>\n",
       "      <td>Recursive Deep Models for Semantic Composition...</td>\n",
       "      <td>[[0.996017]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>W2963010813</td>\n",
       "      <td>Automatic Evaluation and Uniform Filter Cascad...</td>\n",
       "      <td>[[0.9960059]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>W2117130368</td>\n",
       "      <td>A unified architecture for natural language pr...</td>\n",
       "      <td>[[0.9959861]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>W1899794420</td>\n",
       "      <td>Finding Function in Form: Compositional Charac...</td>\n",
       "      <td>[[0.9959631]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>W1524333225</td>\n",
       "      <td>The Kaldi Speech Recognition Toolkit</td>\n",
       "      <td>[[0.9959564]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>W2108069432</td>\n",
       "      <td>Multi-column deep neural network for traffic s...</td>\n",
       "      <td>[[0.9958321]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>W2158139315</td>\n",
       "      <td>Word Representations: A Simple and General Met...</td>\n",
       "      <td>[[0.99581754]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>W2136922672</td>\n",
       "      <td>A Fast Learning Algorithm for Deep Belief Nets</td>\n",
       "      <td>[[0.9958124]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>W2053229256</td>\n",
       "      <td>High-dimensional signature compression for lar...</td>\n",
       "      <td>[[0.99579906]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>W581956982</td>\n",
       "      <td>An Empirical Exploration of Recurrent Network ...</td>\n",
       "      <td>[[0.9956532]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>W2108563286</td>\n",
       "      <td>Advances in optimizing recurrent networks</td>\n",
       "      <td>[[0.99558645]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>W2166742463</td>\n",
       "      <td>In defense of Nearest-Neighbor based image cla...</td>\n",
       "      <td>[[0.99558544]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>W2251682575</td>\n",
       "      <td>Fast and Robust Neural Network Joint Models fo...</td>\n",
       "      <td>[[0.99552]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>W1976921161</td>\n",
       "      <td>The devil is in the details: an evaluation of ...</td>\n",
       "      <td>[[0.99551326]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>W2167510172</td>\n",
       "      <td>Deep Neural Networks Segment Neuronal Membrane...</td>\n",
       "      <td>[[0.9955132]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "170  W2250489405  Joint Language and Translation Modeling with R...   \n",
       "208  W2131462252  A Scalable Hierarchical Distributed Language M...   \n",
       "240  W2253807446  Building high-level features using large scale...   \n",
       "168  W2964335273    How to Construct Deep Recurrent Neural Networks   \n",
       "213  W2120861206  A fast and simple algorithm for training neura...   \n",
       "233  W2127141656              Connectionist temporal classification   \n",
       "268  W2148708890  A Simple, Fast, and Effective Reparameterizati...   \n",
       "234   W179875071      Recurrent neural network based language model   \n",
       "230  W3016169217        Neural Tree Indexers for Text Understanding   \n",
       "261  W1599016936                      The Winograd schema challenge   \n",
       "109  W2251939518  Recursive Deep Models for Semantic Composition...   \n",
       "288  W2963010813  Automatic Evaluation and Uniform Filter Cascad...   \n",
       "85   W2117130368  A unified architecture for natural language pr...   \n",
       "269  W1899794420  Finding Function in Form: Compositional Charac...   \n",
       "188  W1524333225               The Kaldi Speech Recognition Toolkit   \n",
       "138  W2108069432  Multi-column deep neural network for traffic s...   \n",
       "97   W2158139315  Word Representations: A Simple and General Met...   \n",
       "187  W2136922672     A Fast Learning Algorithm for Deep Belief Nets   \n",
       "143  W2053229256  High-dimensional signature compression for lar...   \n",
       "226   W581956982  An Empirical Exploration of Recurrent Network ...   \n",
       "165  W2108563286          Advances in optimizing recurrent networks   \n",
       "65   W2166742463  In defense of Nearest-Neighbor based image cla...   \n",
       "161  W2251682575  Fast and Robust Neural Network Joint Models fo...   \n",
       "34   W1976921161  The devil is in the details: an evaluation of ...   \n",
       "106  W2167510172  Deep Neural Networks Segment Neuronal Membrane...   \n",
       "\n",
       "              score  \n",
       "170  [[0.99704975]]  \n",
       "208   [[0.9967903]]  \n",
       "240   [[0.9967419]]  \n",
       "168  [[0.99667966]]  \n",
       "213  [[0.99649143]]  \n",
       "233   [[0.9964779]]  \n",
       "268   [[0.9963628]]  \n",
       "234  [[0.99634004]]  \n",
       "230   [[0.9962524]]  \n",
       "261   [[0.9961974]]  \n",
       "109    [[0.996017]]  \n",
       "288   [[0.9960059]]  \n",
       "85    [[0.9959861]]  \n",
       "269   [[0.9959631]]  \n",
       "188   [[0.9959564]]  \n",
       "138   [[0.9958321]]  \n",
       "97   [[0.99581754]]  \n",
       "187   [[0.9958124]]  \n",
       "143  [[0.99579906]]  \n",
       "226   [[0.9956532]]  \n",
       "165  [[0.99558645]]  \n",
       "65   [[0.99558544]]  \n",
       "161     [[0.99552]]  \n",
       "34   [[0.99551326]]  \n",
       "106   [[0.9955132]]  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.sort_values(by=\"score\", ascending=False).head(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da0f4927",
   "metadata": {},
   "source": [
    "# Print Root Paper Abstract and 5 most similar papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f80b726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2963403868: Attention is All you Need\n",
      "The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1. \n"
     ]
    }
   ],
   "source": [
    "print(papers[root_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42ff32c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2250489405: Joint Language and Translation Modeling with Recurrent Neural Networks\n",
      "We present a joint language and translation model based on a recurrent neural network which predicts target words based on an unbounded history of both source and target words. The weaker independence assumptions of this model result in a vastly larger search space compared to related feedforward-based language or translation models. We tackle this issue with a new lattice rescoring algorithm and demonstrate its effectiveness empirically. Our joint model builds on a well known recurrent neural network language model (Mikolov, 2012) augmented by a layer of additional inputs from the source language. We show competitive accuracy compared to the traditional channel model features. Our best results improve the output of a system trained on WMT 2012 French-English data by up to 1.5 BLEU, and by 1.1 BLEU on average across several test sets. \n",
      "\n",
      "\n",
      "\n",
      "W2131462252: A Scalable Hierarchical Distributed Language Model\n",
      "Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words, which was two orders of magnitude faster than the non-hierarchical model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models. \n",
      "\n",
      "\n",
      "\n",
      "W2253807446: Building high-level features using large scale unsupervised learning\n",
      "We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images using unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200×200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8% accuracy in recognizing 20,000 object categories from ImageNet, a leap of 70% relative improvement over the previous state-of-the-art. \n",
      "\n",
      "\n",
      "\n",
      "W2964335273: How to Construct Deep Recurrent Neural Networks\n",
      "Abstract: In this paper, we explore different ways to extend a recurrent neural network (RNN) to a \\textit{deep} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, however, we find three points of an RNN which may be made deeper; (1) input-to-hidden function, (2) hidden-to-hidden transition and (3) hidden-to-output function. Based on this observation, we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators. The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling. The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional, shallow RNNs. \n",
      "\n",
      "\n",
      "\n",
      "W2120861206: A fast and simple algorithm for training neural probabilistic language models\n",
      "In spite of their superior performance, neural probabilistic language models (NPLMs) remain far less widely used than n-gram models due to their notoriously long training times, which are measured in weeks even for moderately-sized datasets. Training NPLMs is computationally expensive because they are explicitly normalized, which leads to having to consider all words in the vocabulary when computing the log-likelihood gradients.\n",
      "\n",
      "We propose a fast and simple algorithm for training NPLMs based on noise-contrastive estimation, a newly introduced procedure for estimating unnormalized continuous distributions. We investigate the behaviour of the algorithm on the Penn Treebank corpus and show that it reduces the training times by more than an order of magnitude without affecting the quality of the resulting models. The algorithm is also more efficient and much more stable than importance sampling because it requires far fewer noise samples to perform well.\n",
      "\n",
      "We demonstrate the scalability of the proposed approach by training several neural language models on a 47M-word corpus with a 80K-word vocabulary, obtaining state-of-the-art results on the Microsoft Research Sentence Completion Challenge dataset. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ids = similarities.sort_values(by=\"score\", ascending=False).head(5)[\"id\"]\n",
    "for id in ids.values:\n",
    "    print(papers[id])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "923d854d",
   "metadata": {},
   "source": [
    "# Testing Milvus Search Functionality (cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74433663",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_paper_embeddings = root_paper_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dafa580f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root_paper_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68839ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}, \"offset\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ec132e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = paper_trail_collection.search(\n",
    "\tdata=[root_paper_embeddings], \n",
    "\tanns_field=\"embeddings\", \n",
    "\tparam=search_params,\n",
    "\tlimit=10, \n",
    "\texpr=None,\n",
    "\tconsistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "033d179b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W1591801644', 'W2962741254', 'W1566289585', 'W2130942839', 'W2996428491', 'W2551396370', 'W2167510172', 'W2108598243', 'W2118434577', 'W2950178297']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b6e4e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5404819250106812, 0.5387341380119324, 0.5350673794746399, 0.5233733654022217, 0.5161704421043396, 0.5135420560836792, 0.5115315318107605, 0.5077880620956421, 0.5074553489685059, 0.5040091276168823]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9338437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = results[0].ids[:5]\n",
    "res_dist = results[0].distances[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b65f9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2996428491: ALBERT: A Lite BERT for Self-supervised Learning of Language\n",
      "  Representations\n",
      "Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at https://github.com/google-research/ALBERT. \n",
      "Distance: 0.5161704421043396\n",
      "\n",
      "\n",
      "W2130942839: Sequence to Sequence Learning with Neural Networks\n",
      "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier. \n",
      "Distance: 0.5233733654022217\n",
      "\n",
      "\n",
      "W1566289585: Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books\n",
      "Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in current datasets. To align movies and books we exploit a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for. \n",
      "Distance: 0.5350673794746399\n",
      "\n",
      "\n",
      "W2962741254: DRAW: A Recurrent Neural Network For Image Generation\n",
      "This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye. \n",
      "Distance: 0.5387341380119324\n",
      "\n",
      "\n",
      "W1591801644: Recurrent Neural Network Regularization\n",
      "We present a simple regularization technique for Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units. Dropout, the most successful technique for regularizing neural networks, does not work well with RNNs and LSTMs. In this paper, we show how to correctly apply dropout to LSTMs, and show that it substantially reduces overfitting on a variety of tasks. These tasks include language modeling, speech recognition, image caption generation, and machine translation. \n",
      "Distance: 0.5404819250106812\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, -1, -1):\n",
    "    print(papers[res_list[i]])\n",
    "    print(f\"Distance: {res_dist[i]}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad6f02c4897e5a2f50ed3c5fec7e665ad608d4dc358906e6dd46ab054316280e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
