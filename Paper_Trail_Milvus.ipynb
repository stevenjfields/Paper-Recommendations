{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36f2c2f-7aa7-4fbd-92f1-b83161f4ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "import pandas as pd\n",
    "from cogdl.oag import oagbert\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import os\n",
    "import pymilvus\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87037365-307e-4574-a86d-ae28217a6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_depth = 2\n",
    "ignore_related = True\n",
    "ignore_referenced = False\n",
    "base_works_url = \"https://api.openalex.org/works\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a67f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Article:\n",
    "    # Keeping track of some needed paper details\n",
    "    id: str\n",
    "    title: str\n",
    "    inverted_abstract: Dict[str, List[int]]\n",
    "    authors: List[str]\n",
    "    host_venue: str\n",
    "    affiliations: List[str]\n",
    "    concepts: List[str]\n",
    "    references: List[str]\n",
    "    related: List[str]\n",
    "\n",
    "    def get_abstract(self) -> str:\n",
    "        abstract = dict()\n",
    "        for k, v in self.inverted_abstract.items():\n",
    "            for i in v:\n",
    "                abstract[i] = k\n",
    "\n",
    "        final = \"\"\n",
    "        for i in sorted(abstract.keys()):\n",
    "            final += abstract[i] + \" \"\n",
    "        return final\n",
    "    \n",
    "    def fetch_references_queries(self):\n",
    "        # open alex only allows 50 OR joins per request\n",
    "        queries = list()\n",
    "        for i in range(0, len(self.references), 50):\n",
    "            queries.append('|'.join(self.references[i:i+50]))\n",
    "        return queries\n",
    "    \n",
    "    def fetch_related_queries(self):\n",
    "        # open alex only allows 50 OR joins per request\n",
    "        queries = list()\n",
    "        for i in range(0, len(self.related), 50):\n",
    "            queries.append('|'.join(self.related[i:i+50]))\n",
    "        return queries\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.id}: {self.title}\\n{self.get_abstract()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5213e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_article(result):\n",
    "    work_id = result[\"id\"].split('/')[-1]\n",
    "    title = result[\"title\"]\n",
    "    inverted_abstract = result['abstract_inverted_index']\n",
    "    authors = [authorship['author']['display_name'] for authorship in result['authorships']]\n",
    "    host_venue = result['host_venue']['publisher']\n",
    "    institutions = list()\n",
    "\n",
    "    for authorship in result['authorships']:\n",
    "        for institution in authorship['institutions']: \n",
    "            if institution['display_name'] not in institutions:\n",
    "                institutions.append(institution['display_name'])\n",
    "\n",
    "    concepts = [concept['display_name'] for concept in result['concepts'] if float(concept['score']) > 0.5]\n",
    "    referenced_works = [work.split('/')[-1] for work in result['referenced_works']]\n",
    "    related_works = [work.split('/')[-1] for work in result['related_works']]\n",
    "\n",
    "    return Article(\n",
    "        work_id,\n",
    "        title if title else \"\",\n",
    "        inverted_abstract if inverted_abstract else {\"\": [0]},\n",
    "        authors,\n",
    "        host_venue if host_venue else \"\",\n",
    "        institutions,\n",
    "        concepts,\n",
    "        referenced_works,\n",
    "        related_works\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063dce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymilvus.connections.connect(\n",
    "    alias='default',\n",
    "    host='localhost',\n",
    "    port='19530'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf02c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    FieldSchema(name='pk', dtype=DataType.VARCHAR, max_length=32, is_primary=True),\n",
    "    FieldSchema(name='embeddings', dtype=DataType.FLOAT_VECTOR, dim=768)\n",
    "]\n",
    "collection_name = 'paper_trail_test'\n",
    "schema = CollectionSchema(fields, \"Testing\")\n",
    "paper_trail_collection = Collection(collection_name, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe1aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4acd78-69c6-4c12-b59f-7c23b14f07b5",
   "metadata": {},
   "source": [
    "# Search for Article Title\n",
    "Edit the title variable below to search for a paper. If not exact then returns 25 most relevant papers in the OpenAlex dataset. Select the paper in the dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c333ad3f-a953-494e-a1de-1e3bde69c92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68974b7b19924050a2d4d1fc945d0504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Title: ', options=('Attention is All you Need', 'Attention Is All You Need', 'Channel At…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"Attention is all you need\"\n",
    "title = title.replace(\" \", \"%20\")\n",
    "req = requests.get(base_works_url+f\"?filter=title.search:{title}\")\n",
    "response = json.loads(req.content)\n",
    "\n",
    "relevant_titles = [result['title'] for result in response['results']]\n",
    "title_selector = widgets.Dropdown(\n",
    "    options=relevant_titles,\n",
    "    value=relevant_titles[0],\n",
    "    description=\"Title: \"\n",
    ")\n",
    "display(title_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d531b454",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Please select correct title above. If done, run all cells below this one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease select correct title above. If done, run all cells below this one.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Please select correct title above. If done, run all cells below this one."
     ]
    }
   ],
   "source": [
    "raise Exception(\"Please select correct title above. If done, run all cells below this one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0ca5f4-8341-4d93-be7b-685485140c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = relevant_titles.index(title_selector.value)\n",
    "papers = dict()\n",
    "root_id = response['results'][index]['id'].split('/')[-1]\n",
    "\n",
    "papers[root_id] = fetch_article(response['results'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60843a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_references = ignore_referenced != True\n",
    "use_related = ignore_related != True\n",
    "\n",
    "related_works: Dict[int, List[Article]] = {}\n",
    "\n",
    "def get_relevant_papers(current_depth: int, previous: List[Article]):\n",
    "    related_works[current_depth] = []\n",
    "    print(current_depth)\n",
    "    for parent in previous:\n",
    "        if use_references and len(parent.references) > 0:\n",
    "            for query in parent.fetch_references_queries():         \n",
    "                req = requests.get(base_works_url + f'?filter=openalex_id:{query}')\n",
    "                res = json.loads(req.content)\n",
    "                for result in res[\"results\"]:\n",
    "                    paper_id = result['id'].split('/')[-1]\n",
    "                    if paper_id not in papers.keys():\n",
    "                        temp = fetch_article(result)\n",
    "                        papers[temp.id] = temp\n",
    "                        related_works[current_depth].append(temp)\n",
    "            \n",
    "        if (use_related and len(parent.related) > 0) or len(parent.references) == 0:\n",
    "            for query in parent.fetch_related_queries():  \n",
    "                req = requests.get(base_works_url + f'?filter=openalex_id:{query}')\n",
    "                res = json.loads(req.content)\n",
    "                for result in res[\"results\"]:\n",
    "                    paper_id = result['id'].split('/')[-1]\n",
    "                    if paper_id not in papers.keys():\n",
    "                        temp = fetch_article(result)\n",
    "                        papers[temp.id] = temp\n",
    "                        related_works[current_depth].append(temp)\n",
    "\n",
    "    if current_depth < max_depth:\n",
    "        get_relevant_papers(current_depth+1, related_works[current_depth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10c6066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "get_relevant_papers(1, [papers[root_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f04e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = oagbert(\"oagbert-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee4469d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./embeddings/\"):\n",
    "    os.mkdir(\"./embeddings/\")\n",
    "\n",
    "files = os.listdir(\"./embeddings/\")\n",
    "files = [file.split('.')[0] for file in files]\n",
    "\n",
    "for key in papers.keys():\n",
    "    curr_paper = papers[key]\n",
    "    input_ids, input_masks, token_type_ids, masked_lm_labels, position_ids, position_ids_second, masked_positions, num_spans = model.build_inputs(\n",
    "        title=curr_paper.title, \n",
    "        abstract=curr_paper.get_abstract(), \n",
    "        venue=curr_paper.host_venue, \n",
    "        authors=curr_paper.authors, \n",
    "        concepts=curr_paper.concepts, \n",
    "        affiliations=curr_paper.affiliations\n",
    "    )\n",
    "\n",
    "    sequence_output, pooled_output = model.bert.forward(\n",
    "        input_ids=torch.LongTensor(input_ids).unsqueeze(0),\n",
    "        token_type_ids=torch.LongTensor(token_type_ids).unsqueeze(0),\n",
    "        attention_mask=torch.LongTensor(input_masks).unsqueeze(0),\n",
    "        output_all_encoded_layers=False,\n",
    "        checkpoint_activations=False,\n",
    "        position_ids=torch.LongTensor(position_ids).unsqueeze(0),\n",
    "        position_ids_second=torch.LongTensor(position_ids_second).unsqueeze(0)\n",
    "    )\n",
    "\n",
    "    pooled_normalized = torch.nn.functional.normalize(pooled_output, p=2, dim=1)\n",
    "\n",
    "    paper_trail_collection.insert([\n",
    "            [key], \n",
    "            [pooled_normalized.tolist()[0]]\n",
    "        ])\n",
    "    \n",
    "paper_trail_collection.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95839e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(paper_trail_collection.num_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c07e0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_params = {\n",
    "    \"metric_type\": \"IP\",\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"params\": {\"nlist\": 128}\n",
    "}\n",
    "\n",
    "paper_trail_collection.create_index(field_name=\"embeddings\", index_params=index_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3f55c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_trail_collection.load()\n",
    "root_paper_embeddings = paper_trail_collection.query(\n",
    "    expr = f'pk == \"{root_id}\"',\n",
    "    output_fields=['embeddings']\n",
    ")\n",
    "root_paper_embeddings = torch.Tensor(root_paper_embeddings[0]['embeddings'])\n",
    "root_paper_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6af4ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_trail_collection.load()\n",
    "root_paper_embeddings = paper_trail_collection.query(\n",
    "    expr = f'pk == \"{root_id}\"',\n",
    "    output_fields=['embeddings']\n",
    ")\n",
    "root_paper_embeddings = torch.Tensor([root_paper_embeddings[0]['embeddings']])\n",
    "\n",
    "paper_keys = list(papers.keys())\n",
    "paper_keys.remove(root_id)\n",
    "\n",
    "cols = [\"id\", \"title\", \"score\"]\n",
    "similarities = pd.DataFrame(columns=cols)\n",
    "\n",
    "for key in paper_keys:\n",
    "    paper_embeddings = paper_trail_collection.query(\n",
    "        expr = f'pk == \"{key}\"',\n",
    "        output_fields=['embeddings']\n",
    "    )\n",
    "    paper_embeddings = torch.Tensor([paper_embeddings[0]['embeddings']])\n",
    "    sim = torch.mm(root_paper_embeddings, paper_embeddings.transpose(0, 1))\n",
    "    results = {\n",
    "        \"id\": [key],\n",
    "        \"title\": [papers[key].title],\n",
    "        \"score\": [sim.detach().numpy()]\n",
    "    }\n",
    "\n",
    "    similarities = pd.concat([similarities, pd.DataFrame(results)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e052225f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>W2259472270</td>\n",
       "      <td>Exploring the limits of language modeling</td>\n",
       "      <td>[[0.996257]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>W2546302380</td>\n",
       "      <td>What is the best multi-stage architecture for ...</td>\n",
       "      <td>[[0.9959775]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>W2141125852</td>\n",
       "      <td>Multi-column deep neural networks for image cl...</td>\n",
       "      <td>[[0.995833]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>W2103305545</td>\n",
       "      <td>Dynamic Pooling and Unfolding Recursive Autoen...</td>\n",
       "      <td>[[0.995832]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>W2551396370</td>\n",
       "      <td>Bidirectional Attention Flow for Machine Compr...</td>\n",
       "      <td>[[0.99576867]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>W1753482797</td>\n",
       "      <td>Recurrent Continuous Translation Models</td>\n",
       "      <td>[[0.99561256]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>W2963625095</td>\n",
       "      <td>Named Entity Recognition with Bidirectional LS...</td>\n",
       "      <td>[[0.9955752]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>W2963846996</td>\n",
       "      <td>A Broad-Coverage Challenge Corpus for Sentence...</td>\n",
       "      <td>[[0.9955398]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>W1970689298</td>\n",
       "      <td>Continuous space language models</td>\n",
       "      <td>[[0.99543154]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>W2112796928</td>\n",
       "      <td>Gradient-based learning applied to document re...</td>\n",
       "      <td>[[0.995391]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>W1586532344</td>\n",
       "      <td>End-to-end continuous speech recognition using...</td>\n",
       "      <td>[[0.99538]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>W2100664567</td>\n",
       "      <td>On Using Very Large Target Vocabulary for Neur...</td>\n",
       "      <td>[[0.99534774]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>W2158108973</td>\n",
       "      <td>Domain adaptation with structural corresponden...</td>\n",
       "      <td>[[0.9952103]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>W1524333225</td>\n",
       "      <td>The Kaldi Speech Recognition Toolkit</td>\n",
       "      <td>[[0.99518]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>W2950635152</td>\n",
       "      <td>Learning Phrase Representations using RNN Enco...</td>\n",
       "      <td>[[0.9951777]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>W2130942839</td>\n",
       "      <td>Sequence to Sequence Learning with Neural Netw...</td>\n",
       "      <td>[[0.99512684]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>W1965154800</td>\n",
       "      <td>Strategies for training large scale neural net...</td>\n",
       "      <td>[[0.99510825]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>W2963026768</td>\n",
       "      <td>Universal Language Model Fine-tuning for Text ...</td>\n",
       "      <td>[[0.9950155]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>W2067438047</td>\n",
       "      <td>Placing search in context</td>\n",
       "      <td>[[0.9949609]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>W2131462252</td>\n",
       "      <td>A Scalable Hierarchical Distributed Language M...</td>\n",
       "      <td>[[0.9949341]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>W2963339397</td>\n",
       "      <td>TriviaQA: A Large Scale Distantly Supervised C...</td>\n",
       "      <td>[[0.9947529]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>W2144161366</td>\n",
       "      <td>A High-Throughput Screening Approach to Discov...</td>\n",
       "      <td>[[0.99469626]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>W1902237438</td>\n",
       "      <td>Effective Approaches to Attention-based Neural...</td>\n",
       "      <td>[[0.99463344]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>W35527955</td>\n",
       "      <td>Fast dropout training</td>\n",
       "      <td>[[0.99462837]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>W2150824314</td>\n",
       "      <td>Automatic evaluation of summaries using N-gram...</td>\n",
       "      <td>[[0.9945632]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "224  W2259472270          Exploring the limits of language modeling   \n",
       "132  W2546302380  What is the best multi-stage architecture for ...   \n",
       "235  W2141125852  Multi-column deep neural networks for image cl...   \n",
       "158  W2103305545  Dynamic Pooling and Unfolding Recursive Autoen...   \n",
       "123  W2551396370  Bidirectional Attention Flow for Machine Compr...   \n",
       "156  W1753482797            Recurrent Continuous Translation Models   \n",
       "220  W2963625095  Named Entity Recognition with Bidirectional LS...   \n",
       "112  W2963846996  A Broad-Coverage Challenge Corpus for Sentence...   \n",
       "159  W1970689298                   Continuous space language models   \n",
       "231  W2112796928  Gradient-based learning applied to document re...   \n",
       "249  W1586532344  End-to-end continuous speech recognition using...   \n",
       "245  W2100664567  On Using Very Large Target Vocabulary for Neur...   \n",
       "117  W2158108973  Domain adaptation with structural corresponden...   \n",
       "188  W1524333225               The Kaldi Speech Recognition Toolkit   \n",
       "236  W2950635152  Learning Phrase Representations using RNN Enco...   \n",
       "13   W2130942839  Sequence to Sequence Learning with Neural Netw...   \n",
       "210  W1965154800  Strategies for training large scale neural net...   \n",
       "111  W2963026768  Universal Language Model Fine-tuning for Text ...   \n",
       "99   W2067438047                          Placing search in context   \n",
       "208  W2131462252  A Scalable Hierarchical Distributed Language M...   \n",
       "121  W2963339397  TriviaQA: A Large Scale Distantly Supervised C...   \n",
       "142  W2144161366  A High-Throughput Screening Approach to Discov...   \n",
       "14   W1902237438  Effective Approaches to Attention-based Neural...   \n",
       "201    W35527955                              Fast dropout training   \n",
       "284  W2150824314  Automatic evaluation of summaries using N-gram...   \n",
       "\n",
       "              score  \n",
       "224    [[0.996257]]  \n",
       "132   [[0.9959775]]  \n",
       "235    [[0.995833]]  \n",
       "158    [[0.995832]]  \n",
       "123  [[0.99576867]]  \n",
       "156  [[0.99561256]]  \n",
       "220   [[0.9955752]]  \n",
       "112   [[0.9955398]]  \n",
       "159  [[0.99543154]]  \n",
       "231    [[0.995391]]  \n",
       "249     [[0.99538]]  \n",
       "245  [[0.99534774]]  \n",
       "117   [[0.9952103]]  \n",
       "188     [[0.99518]]  \n",
       "236   [[0.9951777]]  \n",
       "13   [[0.99512684]]  \n",
       "210  [[0.99510825]]  \n",
       "111   [[0.9950155]]  \n",
       "99    [[0.9949609]]  \n",
       "208   [[0.9949341]]  \n",
       "121   [[0.9947529]]  \n",
       "142  [[0.99469626]]  \n",
       "14   [[0.99463344]]  \n",
       "201  [[0.99462837]]  \n",
       "284   [[0.9945632]]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.sort_values(by=\"score\", ascending=False).head(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da0f4927",
   "metadata": {},
   "source": [
    "# Print Root Paper Abstract and 5 most similar papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f80b726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2963403868: Attention is All you Need\n",
      "The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1. \n"
     ]
    }
   ],
   "source": [
    "print(papers[root_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42ff32c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2259472270: Exploring the limits of language modeling\n",
      "In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon. \n",
      "\n",
      "\n",
      "\n",
      "W2546302380: What is the best multi-stage architecture for object recognition?\n",
      "In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (≫ 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%). \n",
      "\n",
      "\n",
      "\n",
      "W2141125852: Multi-column deep neural networks for image classification\n",
      "Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible, wide and deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks. \n",
      "\n",
      "\n",
      "\n",
      "W2103305545: Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection\n",
      "Paraphrase detection is the task of examining two sentences and determining whether they have the same meaning. In order to obtain high accuracy on this task, thorough syntactic and semantic analysis of the two statements is needed. We introduce a method for paraphrase detection based on recursive autoencoders (RAE). Our unsupervised RAEs are based on a novel unfolding objective and learn feature vectors for phrases in syntactic trees. These features are used to measure the word- and phrase-wise similarity between two sentences. Since sentences may be of arbitrary length, the resulting matrix of similarity measures is of variable size. We introduce a novel dynamic pooling layer which computes a fixed-sized representation from the variable-sized matrices. The pooled representation is then used as input to a classifier. Our method outperforms other state-of-the-art approaches on the challenging MSRP paraphrase corpus. \n",
      "\n",
      "\n",
      "\n",
      "W2551396370: Bidirectional Attention Flow for Machine Comprehension\n",
      "Machine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ids = similarities.sort_values(by=\"score\", ascending=False).head(5)[\"id\"]\n",
    "for id in ids.values:\n",
    "    print(papers[id])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "923d854d",
   "metadata": {},
   "source": [
    "# Testing Milvus Search Functionality (cosine similarity)\n",
    "\n",
    "Slightly different results from above, but still very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74433663",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_paper_embeddings = root_paper_embeddings.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dafa580f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root_paper_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68839ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}, \"offset\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ec132e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = paper_trail_collection.search(\n",
    "\tdata=[root_paper_embeddings], \n",
    "\tanns_field=\"embeddings\", \n",
    "\tparam=search_params,\n",
    "\tlimit=10, \n",
    "\texpr=None,\n",
    "\tconsistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "033d179b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W2551396370', 'W1753482797', 'W2963625095', 'W2963846996', 'W1970689298', 'W2112796928', 'W1586532344', 'W2100664567', 'W2158108973', 'W1524333225']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b6e4e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.995768666267395, 0.9956125617027283, 0.9955751299858093, 0.995539665222168, 0.9954315423965454, 0.9953910112380981, 0.9953799843788147, 0.9953477382659912, 0.9952102899551392, 0.9951800107955933]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b65f9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2551396370: Bidirectional Attention Flow for Machine Comprehension\n",
      "Machine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test. \n",
      "Distance: 0.995768666267395\n",
      "\n",
      "\n",
      "W1753482797: Recurrent Continuous Translation Models\n",
      "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations. \n",
      "Distance: 0.9956125617027283\n",
      "\n",
      "\n",
      "W2963625095: Named Entity Recognition with Bidirectional LSTM-CNNs\n",
      "Named entity recognition is a challenging task that has traditionally required large amounts of knowledge in the form of feature engineering and lexicons to achieve high performance. In this paper, we present a novel neural network architecture that automatically detects word- and character-level features using a hybrid bidirectional LSTM and CNN architecture, eliminating the need for most feature engineering. We also propose a novel method of encoding partial lexicon matches in neural networks and compare it to existing approaches. Extensive evaluation shows that, given only tokenized text and publicly available word embeddings, our system is competitive on the CoNLL-2003 dataset and surpasses the previously reported state of the art performance on the OntoNotes 5.0 dataset by 2.13 F1 points. By using two lexicons constructed from publicly-available sources, we establish new state of the art performance with an F1 score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes, surpassing systems that employ heavy feature engineering, proprietary lexicons, and rich entity linking information. \n",
      "Distance: 0.9955751299858093\n",
      "\n",
      "\n",
      "W2963846996: A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference\n",
      "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement. \n",
      "Distance: 0.995539665222168\n",
      "\n",
      "\n",
      "W1970689298: Continuous space language models\n",
      "This paper describes the use of a neural network language model for large vocabulary continuous speech recognition. The underlying idea of this approach is to attack the data sparseness problem by performing the language model probability estimation in a continuous space. Highly efficient learning algorithms are described that enable the use of training corpora of several hundred million words. It is also shown that this approach can be incorporated into a large vocabulary continuous speech recognizer using a lattice rescoring framework at a very low additional processing time. The neural network language model was thoroughly evaluated in a state-of-the-art large vocabulary continuous speech recognizer for several international benchmark tasks, in particular the Nist evaluations on broadcast news and conversational speech recognition. The new approach is compared to four-gram back-off language models trained with modified Kneser-Ney smoothing which has often been reported to be the best known smoothing method. Usually the neural network language model is interpolated with the back-off language model. In that way, consistent word error rate reductions for all considered tasks and languages were achieved, ranging from 0.4% to almost 1% absolute. \n",
      "Distance: 0.9954315423965454\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(papers[results[0].ids[i]])\n",
    "    print(f\"Distance: {results[0].distances[i]}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad6f02c4897e5a2f50ed3c5fec7e665ad608d4dc358906e6dd46ab054316280e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
